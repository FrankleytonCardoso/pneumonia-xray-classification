{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classificação de Imagens para Diagnóstico Médico\n",
        "## Detecção de Pneumonia em Raios-X com Redes Neurais Convolucionais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importando bibliotecas necessárias\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuração Inicial e Exploração dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurar caminhos do dataset\n",
        "dataset_path = \"/kaggle/input/chest-xray-pneumonia/chest_xray\"\n",
        "train_dir = os.path.join(dataset_path, \"train\")\n",
        "val_dir = os.path.join(dataset_path, \"val\")\n",
        "test_dir = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "# Verificar estrutura do dataset\n",
        "print(\"Conteúdo da pasta dataset:\", os.listdir(dataset_path))\n",
        "print(\"\\nConteúdo da pasta train:\", os.listdir(train_dir))\n",
        "print(\"Conteúdo da pasta val:\", os.listdir(val_dir))\n",
        "print(\"Conteúdo da pasta test:\", os.listdir(test_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Contar número de imagens em cada classe\n",
        "def count_images(directory):\n",
        "    normal_count = len(os.listdir(os.path.join(directory, \"NORMAL\")))\n",
        "    pneumonia_count = len(os.listdir(os.path.join(directory, \"PNEUMONIA\")))\n",
        "    return normal_count, pneumonia_count\n",
        "\n",
        "train_normal, train_pneumonia = count_images(train_dir)\n",
        "val_normal, val_pneumonia = count_images(val_dir)\n",
        "test_normal, test_pneumonia = count_images(test_dir)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"DISTRIBUIÇÃO DAS IMAGENS\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Treino - NORMAL: {train_normal} | PNEUMONIA: {train_pneumonia} | Total: {train_normal + train_pneumonia}\")\n",
        "print(f\"Validação - NORMAL: {val_normal} | PNEUMONIA: {val_pneumonia} | Total: {val_normal + val_pneumonia}\")\n",
        "print(f\"Teste - NORMAL: {test_normal} | PNEUMONIA: {test_pneumonia} | Total: {test_normal + test_pneumonia}\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Visualização de Amostras do Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Função para visualizar imagens de exemplo\n",
        "def visualize_samples(class_path, class_name, num_samples=5):\n",
        "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 3))\n",
        "    image_files = os.listdir(class_path)[:num_samples]\n",
        "    \n",
        "    for i, img_file in enumerate(image_files):\n",
        "        img_path = os.path.join(class_path, img_file)\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        \n",
        "        axes[i].imshow(img, cmap='gray')\n",
        "        axes[i].set_title(f\"{class_name}\\n{img.shape}\")\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\n--- AMOSTRAS DA CLASSE NORMAL ---\")\n",
        "visualize_samples(os.path.join(train_dir, \"NORMAL\"), \"NORMAL\")\n",
        "\n",
        "print(\"\\n--- AMOSTRAS DA CLASSE PNEUMONIA ---\")\n",
        "visualize_samples(os.path.join(train_dir, \"PNEUMONIA\"), \"PNEUMONIA\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Classe Dataset Personalizada com Pré-processamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PneumoniaDataset(Dataset):\n",
        "    \"\"\"Dataset personalizado para imagens de raio-X com pneumonia.\"\"\"\n",
        "    \n",
        "    def __init__(self, root_dir, transform=None, apply_clahe=True):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.apply_clahe = apply_clahe\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        self.classes = ['NORMAL', 'PNEUMONIA']\n",
        "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
        "\n",
        "        for class_name in self.classes:\n",
        "            class_dir = os.path.join(root_dir, class_name)\n",
        "            if not os.path.exists(class_dir):\n",
        "                continue\n",
        "            for img_name in os.listdir(class_dir):\n",
        "                if img_name.lower().endswith(('.jpeg', '.jpg', '.png')):\n",
        "                    img_path = os.path.join(class_dir, img_name)\n",
        "                    self.images.append(img_path)\n",
        "                    self.labels.append(self.class_to_idx[class_name])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Verificar se a imagem foi carregada corretamente\n",
        "        if image is None:\n",
        "            print(f\"Erro ao carregar imagem: {img_path}\")\n",
        "            image = np.zeros((224, 224), dtype=np.uint8)\n",
        "\n",
        "        # Aplicar CLAHE para melhoria de contraste\n",
        "        if self.apply_clahe:\n",
        "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "            image = clahe.apply(image)\n",
        "\n",
        "        # Converter para 3 canais (necessário para a ResNet)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Transformações e Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição das transformações\n",
        "def get_transforms():\n",
        "    \"\"\"Retorna as transformações para treino e teste.\"\"\"\n",
        "    \n",
        "    # Transformações para treino (com data augmentation)\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),   # Inversão horizontal aleatória\n",
        "        transforms.RandomRotation(10),            # Rotação aleatória de até 10 graus\n",
        "        transforms.ColorJitter(brightness=0.1, contrast=0.1),  # Pequenas variações\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Transformações para validação/teste (apenas normalização)\n",
        "    test_transforms = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    return train_transforms, test_transforms\n",
        "\n",
        "# Criar os datasets\n",
        "train_transforms, test_transforms = get_transforms()\n",
        "\n",
        "train_dataset = PneumoniaDataset(root_dir=train_dir, transform=train_transforms)\n",
        "val_dataset = PneumoniaDataset(root_dir=val_dir, transform=test_transforms)\n",
        "test_dataset = PneumoniaDataset(root_dir=test_dir, transform=test_transforms)\n",
        "\n",
        "print(f\"Tamanho do dataset de treino: {len(train_dataset)}\")\n",
        "print(f\"Tamanho do dataset de validação: {len(val_dataset)}\")\n",
        "print(f\"Tamanho do dataset de teste: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parâmetros\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "# Criar os dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "# Verificar um batch\n",
        "images, labels = next(iter(train_loader))\n",
        "print(f\"Formato das imagens: {images.shape}\")\n",
        "print(f\"Formato dos labels: {labels.shape}\")\n",
        "print(f\"Distribuição do batch: {labels.bincount()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualização de Imagens com Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Função para mostrar imagens do dataset\n",
        "def show_augmented_samples(dataset, num_samples=5):\n",
        "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 3))\n",
        "    \n",
        "    for i in range(num_samples):\n",
        "        idx = np.random.randint(len(dataset))\n",
        "        image, label = dataset[idx]\n",
        "        \n",
        "        # Desnormalizar para visualização\n",
        "        img = image.numpy().transpose((1, 2, 0))\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        img = std * img + mean\n",
        "        img = np.clip(img, 0, 1)\n",
        "        \n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(f\"Classe: {dataset.classes[label]}\")\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Amostras do dataset de treino (com data augmentation):\")\n",
        "show_augmented_samples(train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Definição do Modelo (ResNet18 com Transfer Learning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "class PneumoniaCNN(nn.Module):\n",
        "    \"\"\"Modelo CNN para classificação de pneumonia usando ResNet18 pré-treinada.\"\"\"\n",
        "    \n",
        "    def __init__(self, num_classes=2, freeze_backbone=True):\n",
        "        super(PneumoniaCNN, self).__init__()\n",
        "        \n",
        "        # Carregar ResNet18 pré-treinada\n",
        "        self.backbone = models.resnet18(pretrained=True)\n",
        "        \n",
        "        # Congelar as camadas do backbone (opcional)\n",
        "        if freeze_backbone:\n",
        "            for param in self.backbone.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "        # Substituir a última camada fully connected\n",
        "        num_features = self.backbone.fc.in_features\n",
        "        self.backbone.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_features, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "# Instanciar o modelo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = PneumoniaCNN(num_classes=2).to(device)\n",
        "\n",
        "# Verificar o modelo\n",
        "print(model)\n",
        "print(f\"\\nModelo carregado em: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Funções de Treinamento e Validação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
        "    \"\"\"Treina o modelo por uma época.\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Estatísticas\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def validate(model, loader, criterion, device):\n",
        "    \"\"\"Valida o modelo no conjunto de validação.\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Treinamento do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hiperparâmetros\n",
        "NUM_EPOCHS = 10\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# Loss function e otimizador\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
        "\n",
        "# Listas para armazenar o histórico\n",
        "train_losses, val_losses = [], []\n",
        "train_accs, val_accs = [], []\n",
        "best_val_acc = 0.0\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"INICIANDO TREINAMENTO\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Treinamento\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "\n",
        "    # Validação\n",
        "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    # scheduler step\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Salvar melhor modelo\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "    # Print do progresso\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
        "    print(f\"  Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
        "    print(f\"  LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(f\"TREINAMENTO CONCLUÍDO! Melhor acurácia de validação: {best_val_acc*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Visualização do Histórico de Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot da loss\n",
        "ax1.plot(range(1, NUM_EPOCHS+1), train_losses, 'b-', label='Treino')\n",
        "ax1.plot(range(1, NUM_EPOCHS+1), val_losses, 'r-', label='Validação')\n",
        "ax1.set_xlabel('Épocas')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Loss durante o Treinamento')\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "\n",
        "# Plot da acurácia\n",
        "ax2.plot(range(1, NUM_EPOCHS+1), train_accs, 'b-', label='Treino')\n",
        "ax2.plot(range(1, NUM_EPOCHS+1), val_accs, 'r-', label='Validação')\n",
        "ax2.set_xlabel('Épocas')\n",
        "ax2.set_ylabel('Acurácia')\n",
        "ax2.set_title('Acurácia durante o Treinamento')\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Avaliação no Conjunto de Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar o melhor modelo\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "# Avaliar no teste\n",
        "test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"RESULTADOS NO CONJUNTO DE TESTE\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Loss no teste: {test_loss:.4f}\")\n",
        "print(f\"Acurácia no teste: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Matriz de Confusão e Relatório de Classificação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Coletar todas as predições\n",
        "def get_all_predictions(model, loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    return np.array(all_labels), np.array(all_preds)\n",
        "\n",
        "y_true, y_pred = get_all_predictions(model, test_loader, device)\n",
        "\n",
        "# Matriz de confusão\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NORMAL', 'PNEUMONIA'], yticklabels=['NORMAL', 'PNEUMONIA'])\n",
        "plt.xlabel('Predito')\n",
        "plt.ylabel('Verdadeiro')\n",
        "plt.title('Matriz de Confusão - Conjunto de Teste')\n",
        "plt.show()\n",
        "\n",
        "# Relatório de classificação\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_true, y_pred, target_names=['NORMAL', 'PNEUMONIA']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Visualização de Predições (Exemplos Corretos e Incorretos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_predictions(model, dataset, device, num_images=10):\n",
        "    \"\"\"Plota exemplos do dataset com as predições do modelo.\n",
        "       - Verde: classificação correta\n",
        "       - Vermelho: classificação incorreta\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    indices = np.random.choice(len(dataset), num_images, replace=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, idx in enumerate(indices):\n",
        "            image, label = dataset[idx]\n",
        "            image_tensor = image.unsqueeze(0).to(device)\n",
        "\n",
        "            output = model(image_tensor)\n",
        "            _, predicted = torch.max(output, 1)\n",
        "\n",
        "            # Preparar imagem para visualização\n",
        "            img = image.cpu().numpy().transpose((1, 2, 0))\n",
        "            mean = np.array([0.485, 0.456, 0.406])\n",
        "            std = np.array([0.229, 0.224, 0.225])\n",
        "            img = std * img + mean\n",
        "            img = np.clip(img, 0, 1)\n",
        "\n",
        "            # Definir cor do título\n",
        "            color = 'green' if predicted.item() == label else 'red'\n",
        "            title = f'V: {dataset.classes[label]} | P: {dataset.classes[predicted.item()]}'\n",
        "            \n",
        "            axes[i].imshow(img)\n",
        "            axes[i].set_title(title, color=color)\n",
        "            axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\nExemplos de Classificações (Verde = Correto, Vermelho = Incorreto):\")\n",
        "plot_predictions(model, test_dataset, device, num_images=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Análise de Erros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identificar índices de erros\n",
        "error_indices = np.where(y_true != y_pred)[0]\n",
        "\n",
        "print(f\"Total de erros: {len(error_indices)} de {len(y_true)} ({len(error_indices)/len(y_true)*100:.2f}%)\")\n",
        "\n",
        "if len(error_indices) > 0:\n",
        "    print(\"\\nExemplos de erros:\")\n",
        "    # Mostrar alguns exemplos de erros\n",
        "    num_errors_to_show = min(5, len(error_indices))\n",
        "    \n",
        "    fig, axes = plt.subplots(1, num_errors_to_show, figsize=(15, 3))\n",
        "    if num_errors_to_show == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for i, idx in enumerate(error_indices[:num_errors_to_show]):\n",
        "        image, label = test_dataset[idx]\n",
        "        \n",
        "        # Preparar imagem\n",
        "        img = image.cpu().numpy().transpose((1, 2, 0))\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        img = std * img + mean\n",
        "        img = np.clip(img, 0, 1)\n",
        "        \n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(f'V: {test_dataset.classes[label]} | P: {test_dataset.classes[y_pred[idx]]}')\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. Conclusão\n",
        "\n",
        "**Resultados Alcançados:**\n",
        "- Acurácia no teste: **76,12%**\n",
        "- Modelo: ResNet18 com transfer learning\n",
        "- Técnicas utilizadas: CLAHE para contraste, data augmentation, fine-tuning\n",
        "\n",
        "**Possíveis Melhorias Futuras:**\n",
        "1. Treinar por mais épocas com early stopping\n",
        "2. Testar arquiteturas mais robustas (EfficientNet, DenseNet)\n",
        "3. Expandir a base de dados com mais exemplos\n",
        "4. Implementar validação cruzada\n",
        "5. Utilizar técnicas de explicabilidade (Grad-CAM) para entender as decisões do modelo"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
